* Exploring validation metrics for offline model-based optimisation with diffusion models

** Installation

Please see =INSTALL.org=.

When this is done, cd into =exps= and run =cp env.sh.bak env.sh= and modify =env.sh= to define the following environment variables. Here is an example:

#+BEGIN_SRC bash
export SAVEDIR=<path to store experiment checkpoints>
export MUJOCO_PY_MUJOCO_PATH=~/bin/mujoco/mujoco210
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${MUJOCO_PY_MUJOCO_PATH}/bin:/usr/lib/nvidia
#+END_SRC

** Experiments

The =exps= folder is is where experiments are launched from, and experiments are launched by invoking =main.sh=. Its usage is as follows:

#+BEGIN_SRC
# run source env.sh before running main.sh
bash main.sh <cls|sbgm> <experiment name> <path to json file>
#+END_SRC

Let's break this down from left to right:

- =cls= for training a classifier (i.e. the oracle regression model), =sbgm= for diffusion model.
- =<experiment name>= is the name of the experiment, whose directory of results and checkpoints will be stored in =$SAVEDIR/<experiment name>/<experiment id>=. The experiment ID by default is taken from =$SLURM_JOB_ID= (because that is what I use internally), but in a non-Slurm environment this will be /undefined/. Therefore the script will replace it with Unix time. (If this is not desirable you can modify the script to do something else.)
- Experiments are defined not through a messy string of argparse arguments but instead via a JSON dictionary. You can see all the possible options by viewing the respective dataclass in =trainval.py=.

By default, this script will copy the code to =$SAVEDIR/<experiment name>/<experiment id>/code= and cd into that directory to run the experiment. To avoid this simply set =RUN_LOCAL=1=.

** Reproduction

Due to large file sizes I have only included the pretrained checkpoints for the oracles. These are needed to run the experiments defined in =exps/json= .

First download the checkpoints from here: TODO.


